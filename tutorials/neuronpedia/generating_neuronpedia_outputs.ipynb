{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Outputs for Neuronpedia Upload\n",
    "\n",
    "We use Callum McDougall's `sae_vis` library for generating JSON data to upload to Neuronpedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sboughorbel/.cache/huggingface/hub/models--jbloom--GPT2-Small-SAEs-Reformatted/snapshots/5bd69d8ccac6b19d91934c5aeed4866f8b6e50c7/blocks.0.hook_resid_pre\n"
     ]
    }
   ],
   "source": [
    "from sae_lens.toolkit.pretrained_saes import download_sae_from_hf\n",
    "import os\n",
    "\n",
    "MODEL_ID = \"gpt2-small\"\n",
    "SAE_ID = \"res-jb\"\n",
    "\n",
    "(_, SAE_WEIGHTS_PATH, _) = download_sae_from_hf(\n",
    "    \"jbloom/GPT2-Small-SAEs-Reformatted\", \"blocks.0.hook_resid_pre\"\n",
    ")\n",
    "\n",
    "SAE_PATH = os.path.dirname(SAE_WEIGHTS_PATH)\n",
    "print(SAE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save JSON to neuronpedia_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sboughorbel/.cache/huggingface/hub/models--jbloom--GPT2-Small-SAEs-Reformatted/snapshots/5bd69d8ccac6b19d91934c5aeed4866f8b6e50c7/blocks.0.hook_resid_pre\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sboughorbel/Projects/NeuroX/code/models/gpt2-small/pytorch_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(SAE_PATH)\n\u001b[1;32m      4\u001b[0m NP_OUTPUT_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sboughorbel/Projects/NeuroX/code/SAELens-Fork/neuropedia\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronpediaRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAE_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNP_OUTPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparsity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_batches_to_sample_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_prompts_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features_at_a_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_batch_inclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_batch_inclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m runner\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Projects/NeuroX/code/SAELens-Fork/sae_lens/analysis/neuronpedia_runner.py:90\u001b[0m, in \u001b[0;36mNeuronpediaRunner.__init__\u001b[0;34m(self, sae_id, sae_path, outputs_dir, sparsity_threshold, n_batches_to_sample_from, n_prompts_to_select, n_features_at_a_time, start_batch_inclusive, end_batch_inclusive)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_autoencoder \u001b[38;5;241m=\u001b[39m SparseAutoencoder\u001b[38;5;241m.\u001b[39mload_from_pretrained(\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae_path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     89\u001b[0m loader \u001b[38;5;241m=\u001b[39m LMSparseAutoencoderSessionloader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_autoencoder\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_store \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_sae_training_group_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_autoencoder\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_autoencoder\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mhook_point_layer\n",
      "File \u001b[0;32m~/Projects/NeuroX/code/SAELens-Fork/sae_lens/training/session_loader.py:29\u001b[0m, in \u001b[0;36mLMSparseAutoencoderSessionloader.load_sae_training_group_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sae_training_group_session\u001b[39m(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     24\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[HookedRootModule, SparseAutoencoderDictionary, ActivationsStore]:\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Loads a session for training a sparse autoencoder on a language model.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     31\u001b[0m     activations_loader \u001b[38;5;241m=\u001b[39m ActivationsStore\u001b[38;5;241m.\u001b[39mfrom_config(\n\u001b[1;32m     32\u001b[0m         model,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg,\n\u001b[1;32m     34\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/NeuroX/code/SAELens-Fork/sae_lens/training/session_loader.py:69\u001b[0m, in \u001b[0;36mLMSparseAutoencoderSessionloader.get_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mLoads a model from transformer lens.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mAbstracted to allow for easy modification.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Todo: add check that model_name is valid\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_class_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Projects/NeuroX/code/SAELens-Fork/sae_lens/training/load_model.py:116\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_class_name, model_name, device)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHookedTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    115\u001b[0m     home_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sboughorbel/Projects/NeuroX/code/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 116\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhome_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/pytorch_model.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     model \u001b[38;5;241m=\u001b[39m HookedTransformer(cfg)\n\u001b[1;32m    118\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/neurox/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/neurox/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/neurox/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sboughorbel/Projects/NeuroX/code/models/gpt2-small/pytorch_model.bin'"
     ]
    }
   ],
   "source": [
    "from sae_lens.analysis.neuronpedia_runner import NeuronpediaRunner\n",
    "\n",
    "print(SAE_PATH)\n",
    "NP_OUTPUT_FOLDER = \"/home/sboughorbel/Projects/NeuroX/code/SAELens-Fork/neuropedia\"\n",
    "\n",
    "runner = NeuronpediaRunner(\n",
    "    sae_id=SAE_ID,\n",
    "    sae_path=SAE_PATH,\n",
    "    outputs_dir=NP_OUTPUT_FOLDER,\n",
    "    sparsity_threshold=-5,\n",
    "    n_batches_to_sample_from=2**12,\n",
    "    n_prompts_to_select=4096*6,\n",
    "    n_features_at_a_time=24,\n",
    "    start_batch_inclusive=1,\n",
    "    end_batch_inclusive=1,\n",
    ")\n",
    "\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Neuronpedia\n",
    "#### This currently only works if you have admin access to the Neuronpedia database via localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers that fix weird NaN stuff\n",
    "from decimal import Decimal\n",
    "from typing import Any\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "FEATURE_OUTPUTS_FOLDER = runner.outputs_dir\n",
    "\n",
    "def nanToNeg999(obj: Any) -> Any:\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: nanToNeg999(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [nanToNeg999(v) for v in obj]\n",
    "    elif (isinstance(obj, float) or isinstance(obj, Decimal)) and math.isnan(obj):\n",
    "        return -999\n",
    "    return obj\n",
    "\n",
    "\n",
    "class NanConverter(json.JSONEncoder):\n",
    "    def encode(self, o: Any, *args: Any, **kwargs: Any):\n",
    "        return super().encode(nanToNeg999(o), *args, **kwargs)\n",
    "\n",
    "\n",
    "# Server info\n",
    "host = \"http://localhost:3000\"\n",
    "\n",
    "# Upload alive features\n",
    "for file_name in os.listdir(FEATURE_OUTPUTS_FOLDER):\n",
    "    if file_name.startswith(\"batch-\") and file_name.endswith(\".json\"):\n",
    "        print(\"Uploading file: \" + file_name)\n",
    "        file_path = os.path.join(FEATURE_OUTPUTS_FOLDER, file_name)\n",
    "        f = open(file_path, \"r\")\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Replace NaNs\n",
    "        data_fixed = json.dumps(data, cls=NanConverter)\n",
    "        data = json.loads(data_fixed)\n",
    "\n",
    "        url = host + \"/api/local/upload-features\"\n",
    "        resp = requests.post(\n",
    "            url,\n",
    "            json=data,\n",
    "        )\n",
    "\n",
    "# Upload dead feature stubs\n",
    "skipped_path = os.path.join(FEATURE_OUTPUTS_FOLDER, \"skipped_indexes.json\")\n",
    "f = open(skipped_path, \"r\")\n",
    "data = json.load(f)\n",
    "url = host + \"/api/local/upload-dead-features\"\n",
    "resp = requests.post(\n",
    "    url,\n",
    "    json=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Automatically validate the uploaded data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
